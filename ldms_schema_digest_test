#!/usr/bin/env python3
#
# Test LDMS Schema digest capability
#
# Test scenario:
# - start sampler
# - start agg-1
# - ldms_ls -vv to sampler
# - ldms_ls -vv to agg-1
# - dir agg-1 over Python
# - lookup agg-1 over Python
# - compare digest strings

import os
import re
import pwd
import sys
import json
import time
import argparse
import TADA
import logging
import atexit

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, LDMSDContainer, process_args, \
                      add_common_args, jprint, parse_ldms_ls

if __name__ != "__main__":
    raise RuntimeError("This should not be impoarted as a module.")

class Debug(object):
    pass
D = Debug()

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())

#### default values #### ---------------------------------------------
sbin_ldmsd = find_executable("ldmsd")
if sbin_ldmsd:
    default_prefix, a, b = sbin_ldmsd.rsplit('/', 2)
else:
    default_prefix = "/opt/ovis"

#### argument parsing #### -------------------------------------------
ap = argparse.ArgumentParser(description = "Test LDMS Schema digest capability" )
add_common_args(ap)
args = ap.parse_args()
process_args(args)

#### config variables #### ------------------------------
USER = args.user
PREFIX = args.prefix
COMMIT_ID = args.commit_id
SRC = args.src
CLUSTERNAME = args.clustername
DB = args.data_root
LDMSD_PORT = 10000
STORE_ROOT = "/store" # path inside container (agg-2)

#### spec #### -------------------------------------------------------
common_plugin_config = [
        "component_id=%component_id%",
        "instance=%hostname%/%plugin%",
        "producer=%hostname%",
    ]
spec = {
    "name" : CLUSTERNAME,
    "description" : "{}'s test cluster".format(USER),
    "type" : "NA",
    "templates" : { # generic template can apply to any object by "!extends"
        "compute-node" : {
            "daemons" : [
                {
                    "name" : "sshd", # for debugging
                    "type" : "sshd",
                },
                {
                    "name" : "sampler-daemon",
                    "!extends" : "ldmsd-sampler",
                },
            ],
        },
        "sampler_plugin" : {
            "interval" : 1000000,
            "offset" : 0,
            "config" : common_plugin_config,
            "start" : True,
        },
        "ldmsd-base" : {
            "type" : "ldmsd",
            "listen" : [
                { "port" : LDMSD_PORT, "xprt" : "sock" },
            ],
            #"listen_port" : LDMSD_PORT,
            #"listen_xprt" : "sock",
            #"listen_auth" : "none",
        },
        "ldmsd-sampler" : {
            "!extends" : "ldmsd-base",
            "samplers" : [
                {
                    "plugin" : "meminfo",
                    "!extends" : "sampler_plugin",
                },
            ],
        },
        "prdcr" : {
            "host" : "%name%",
            "port" : LDMSD_PORT,
            "xprt" : "sock",
            "type" : "active",
            "interval" : 1000000,
        },
        "ldmsd-aggregator" : {
            "!extends" : "ldmsd-base",
            "config" : [ # additional config applied after prdcrs
                "prdcr_start_regex regex=.*",
                "updtr_add name=all interval=1000000 offset=%offset%",
                "updtr_prdcr_add name=all regex=.*",
                "updtr_start name=all"
            ],
        },
    }, # templates
    "nodes" : [
        {
            "hostname" : "node-1",
            "component_id" : 1,
            "!extends" : "compute-node",
        },
        {
            "hostname" : "agg-1",
            "!extends" : "compute-node",
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "agg",
                    "!extends" : "ldmsd-aggregator",
                    "offset" : 200000,
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "node-1",
                            "!extends" : "prdcr",
                        }
                    ],
                },
            ]
        },
        {
            "hostname" : "headnode",
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
            ]
        },
    ], # nodes

    #"image": "ovis-centos-build:slurm",
    "cap_add": [ "SYS_PTRACE", "SYS_ADMIN" ],
    "image": args.image,
    "ovis_prefix": PREFIX,
    "env" : { "FOO": "BAR" },
    "mounts": [
        "{}:/db:rw".format(DB),
        "{0}:{1}:ro".format(os.path.realpath(sys.path[0]), "/tada-src"),
    ] + args.mount +
    ( ["{0}:{0}:ro".format(SRC)] if SRC else [] ),
}

#### test definition ####

test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "ldms_schema_digest_test",
                 test_desc = "Test LDMS Schema digest capability",
                 test_user = args.user,
                 commit_id = COMMIT_ID,
                 tada_addr = args.tada_addr)
test.add_assertion(1, "No schema digest from ldms_ls -v sampler")
test.add_assertion(2, "Schema digest from ldms_ls -vv sampler is not empty")
test.add_assertion(3, "Schema digest from ldms_ls -vv agg-1 is not empty")
test.add_assertion(4, "Schema digest from Python ldms dir agg-1 is not empty")
test.add_assertion(5, "Schema digest from Python ldms lokoup agg-1 is not empty")
test.add_assertion(6, "All digests of the same set are the same")
test.add_assertion(7, "Sets of same schema yield the same digest")
test.add_assertion(8, "Different schema (1-off metric) yield different digest")

#### Helper Functions ####
def ldms_ls(host, port = LDMSD_PORT, lvv = ""):
    # lvv could be '-l', '-lv', '-lvv', '-v', or '-vv'
    try:
        args = lvv
        rc, out = headnode.exec_run("bash -c 'ldms_ls {args} -x sock -p {port}" \
                                    "     -h {host} 2>/dev/null'" \
                                    .format(host=host, port=port, args=args))
        if lvv:
            return parse_ldms_ls(out)
        else:
            return out.splitlines()
    except:
        return None

def verify_ls(data, test_id, digest = True):
    global missing_digests
    if list(data) != ['node-1/meminfo']:
        test.assert_test(test_id, False, "Bad data")
        return
    dgst = data['node-1/meminfo']['meta']['schema_digest']
    if digest:
        b = (dgst is not None)
        if not b:
            missing_digests = True
    else:
        b = (dgst is None)
    test.assert_test(test_id, b, "verified" if b else "bad digest")

#### Start! ####
cluster = None
test.start()

@atexit.register
def at_exit():
    rc = test.finish()
    if cluster is not None:
        cluster.remove()
    os._exit(rc)

log.info("-- Get or create the cluster --")
cluster = LDMSDCluster.get(spec["name"], create = True, spec = spec)

headnode = cluster.get_container("headnode")
agg1 = cluster.get_container("agg-1")
node1 = cluster.get_container("node-1")

log.info("-- Start daemons --")
cluster.start_daemons()
cluster.make_known_hosts()

log.info("... wait a bit to make sure ldmsd's are up")
time.sleep(5)

missing_digests = False

data_1 = ldms_ls("node-1", lvv = "-v")
verify_ls(data_1, 1, digest=False)
data_2 = ldms_ls("node-1", lvv = "-vv")
verify_ls(data_2, 2)
data_3 = ldms_ls("agg-1", lvv = "-vv")
verify_ls(data_3, 3)

while True: # will break
    rc, out = headnode.exec_run("python3 /tada-src/python/ldms_schema_digest.py")
    assert(rc == 0)
    obj = json.loads(out)
    dir_digest_str = obj.get("dir_digest_str")
    set_digest_str = obj.get("set_digest_str")
    if not dir_digest_str:
        missing_digests = True
        test.assert_test(4, False, "missing digest str")
        break
    test.assert_test(4, True, "verified")
    if not set_digest_str:
        missing_digests = True
        test.assert_test(5, False, "missing digest str")
        break
    test.assert_test(5, True, "verified")
    break

if not missing_digests:
    # verify that all the digests are the same
    s = set([
            data_2['node-1/meminfo']['meta']['schema_digest'],
            data_3['node-1/meminfo']['meta']['schema_digest'],
            dir_digest_str,
            set_digest_str
        ])
    test.assert_test(6, len(s) == 1, "")

# Run 3 made-up samplers to test schemas of same names with 1-off metric
t1 = headnode.exec_interact("/usr/bin/python3 -i /tada-src/python/digest_samp.py -p 10001")
t2 = headnode.exec_interact("/usr/bin/python3 -i /tada-src/python/digest_samp.py -p 10002 -S 2")
t3 = headnode.exec_interact("/usr/bin/python3 -i /tada-src/python/digest_samp.py -p 10003")
time.sleep(2)
rc, out = headnode.exec_run("/usr/bin/python3 /tada-src/python/digest_agg.py 10001 10002 10003")
assert(rc == 0)
obj = json.loads(out)
assert(type(obj) == dict)
assert(len(obj) == 3)

#test.add_assertion(7, "Sets of same schema yield the same digest")
test.assert_test(7, obj["port_10001"] == obj["port_10003"], "check")
#test.add_assertion(8, "Different schema (1-off metric) yield different digest")
test.assert_test(8, obj["port_10002"] != obj["port_10003"], "check")

# see `at_exit()` function
